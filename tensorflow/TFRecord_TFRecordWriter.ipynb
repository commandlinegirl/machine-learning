{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading and processing data efficiently in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notes for TF tools for streamlining and for input data processing\n",
    "(following \"Learning TensorFlow\" by Hope, Resheff, Lieder (O'Reilly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TFRecord\n",
    "\n",
    "A binary file containing serialized input data. Serialization is based on protocol buffers.\n",
    "All data is held in one block of memory, cutting on the read-from-memory time.\n",
    "Many TF tools are optimized for TFRecords.\n",
    "\n",
    "### TFRecordWriter\n",
    "\n",
    "Note: it's actually rather slow and storage consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/tmp/loading/mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/loading/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/loading/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/loading/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/loading/mnist/t10k-labels-idx1-ubyte.gz\n",
      "saving train\n",
      "saving test\n",
      "saving validation\n",
      "(784,)\n",
      "<type 'numpy.ndarray'>\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "data_sets = mnist.read_data_sets(DATA_DIR,\n",
    "                                 dtype=tf.uint8,\n",
    "                                 reshape=False,\n",
    "                                 validation_size=1000)\n",
    "\n",
    "# data_sets is already divided\n",
    "data_splits = [\"train\", \"test\", \"validation\"]\n",
    "for d in range(len(data_splits)):\n",
    "    print(\"saving \" + data_splits[d])\n",
    "    data_set = data_sets[d]\n",
    "\n",
    "    filename = os.path.join(DATA_DIR, data_splits[d] + '.tfrecords')\n",
    "    \n",
    "    # Create a TFRecord writer\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    \n",
    "    for index in range(data_set.images.shape[0]):\n",
    "        image = data_set.images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "            feature={\n",
    "                'height': tf.train.Feature(\n",
    "                    int64_list=tf.train.Int64List(\n",
    "                        value=[data_set.images.shape[1]])),\n",
    "                'width': tf.train.Feature(\n",
    "                    int64_list=tf.train.Int64List(\n",
    "                        value=[data_set.images.shape[2]])),\n",
    "                'depth': tf.train.Feature(\n",
    "                    int64_list=tf.train.Int64List(\n",
    "                        value=[data_set.images.shape[3]])),\n",
    "                'label': tf.train.Feature(\n",
    "                    int64_list=tf.train.Int64List(\n",
    "                        value=[int(data_set.labels[index])])),\n",
    "                'image_raw': tf.train.Feature(\n",
    "                    bytes_list=tf.train.BytesList(\n",
    "                        value=[image]))}\n",
    "        ))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "filename = os.path.join(DATA_DIR, 'train.tfrecords')\n",
    "record_iterator = tf.python_io.tf_record_iterator(filename)\n",
    "seralized_img_example = next(record_iterator)\n",
    "\n",
    "example = tf.train.Example()\n",
    "example.ParseFromString(seralized_img_example)\n",
    "image = example.features.feature['image_raw'].bytes_list.value\n",
    "label = example.features.feature['label'].int64_list.value[0]\n",
    "width = example.features.feature['width'].int64_list.value[0]\n",
    "height = example.features.feature['height'].int64_list.value[0]\n",
    "\n",
    "img_flat = np.fromstring(image[0], dtype=np.uint8)\n",
    "img_reshaped = img_flat.reshape((height, width, -1))\n",
    "\n",
    "print\n",
    "print(img_flat.shape)\n",
    "print(type(img_reshaped))\n",
    "print(img_reshaped.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Other notes:\n",
    "- feed_dict - does a single-threaded copy of data from the Python runtimeto the TensorFlow runtime; causing latency and slowdowns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
