{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf # a default graph is created with a tf import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the contents of these variables are the *outputs* of the operations\n",
    "# and not operations themselves\n",
    "\n",
    "a = tf.constant(5, name = \"my_a\") # output of a const value\n",
    "b = tf.constant(2, name = \"my_b\")\n",
    "c = tf.constant(3, name = \"my_c\")\n",
    "\n",
    "d = tf.multiply(a, b, name = \"my_d\")\n",
    "e = tf.add(c, b, name = \"my_e\")\n",
    "f = tf.subtract(d, e, name = \"my_f\")\n",
    "g = tf.logical_xor(True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 2, 3, 10, 5, 5]\n",
      "<type 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "# the graph computes only essential nodes according to the \n",
    "# dependencies (here - of \"outs\")\n",
    "with tf.Session() as sess:\n",
    "    fetches = [a,b,c,d,e,f]  # fetches hold the element of the graph\n",
    "                             # we want to compute\n",
    "    outs = sess.run(fetches) # execution\n",
    "    \n",
    "print(outs)\n",
    "print(type(outs[0]))         # list of numpy elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"my_f:0\", shape=(), dtype=int32)\n",
      "<type 'numpy.int32'>\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# we can perform the same runs in the same graph multiple times\n",
    "# but each in a new session\n",
    "with tf.Session() as sess:\n",
    "    out = sess.run(f)\n",
    "print(type(f))\n",
    "print(f)\n",
    "print(type(out))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3,)\n",
      "(3, 1)\n",
      "[[ 50]\n",
      " [122]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([[1,2,3], [4,5,6]])\n",
    "x = tf.constant([7, 8, 9])\n",
    "print(A.get_shape()) \n",
    "print(x.get_shape())\n",
    "# need to reshape x\n",
    "x = tf.expand_dims(x, 1)\n",
    "print(x.get_shape())\n",
    "b = tf.matmul(A, x)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "print(b.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7f979896ad50>\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f979896a850>\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f979896ad50>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# compare the default graph and another one\n",
    "print(tf.get_default_graph())\n",
    "g = tf.Graph()\n",
    "print(g)\n",
    "\n",
    "# check which graph is associated with a node\n",
    "s = tf.constant(10)\n",
    "print(s.graph)\n",
    "\n",
    "# use contect manager (with statement) to run with a given graph\n",
    "with g.as_default():\n",
    "    print(g is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"my:0\", shape=(), dtype=int32)\n",
      "Tensor(\"my_1:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    print(tf.constant(1, name = \"my\")) # names should be unique *in the same graph*;\n",
    "    print(tf.constant(2, name = \"my\")) # tf adds \"_<n>\" otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"prefix_A/p:0\", shape=(), dtype=int32)\n",
      "Tensor(\"prefix_A/q:0\", shape=(), dtype=int32)\n",
      "Tensor(\"prefix_A/prefix_B/r:0\", shape=(), dtype=int32)\n",
      "Tensor(\"prefix_A/prefix_B/s:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    with tf.name_scope(\"prefix_A\"):\n",
    "        print(tf.constant(1, name = \"p\")) \n",
    "        print(tf.constant(2, name = \"q\"))\n",
    "        with tf.name_scope(\"prefix_B\"):\n",
    "            print(tf.constant(11, name = \"r\"))\n",
    "            print(tf.constant(22, name = \"s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "Variables are a special type of Tensors that can maintain a \"fixed\" state in a graph.\n",
    "Using them requires they are initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1, 4) dtype=float32_ref>\n",
      "It'll throw with a mesg Attempting to use uninitialized value Variable_6\n",
      "[[-0.2057834   0.60403806 -1.5744915  -0.70292491]]\n"
     ]
    }
   ],
   "source": [
    "init_val = tf.random_normal((1, 4), 0 , 1)\n",
    "var = tf.Variable(init_val)\n",
    "print(var)\n",
    "\n",
    "try:\n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(var)\n",
    "except tf.errors.FailedPreconditionError:\n",
    "    print \"It'll throw with a mesg Attempting to use uninitialized value Variable_6\"\n",
    "\n",
    "# Now initialize the Variable\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    result = sess.run(var)\n",
    "    print(result)\n",
    "    \n",
    "# with each run a new Variable is created - the name will have \"_n\" appended to name: 'Variable_11:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# if shape is None or empty, anu size is accepted\n",
    "pa = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "print(pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.22163916]\n",
      " [-4.7881918 ]\n",
      " [-3.03102112]\n",
      " [ 1.55688775]\n",
      " [ 0.86975569]]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "_x = np.random.randn(5, 10)\n",
    "_y = np.random.randn(10, 1)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=(5, 10))\n",
    "    y = tf.placeholder(tf.float32, shape=(10, 1))\n",
    "    xy = tf.matmul(x, y)\n",
    "    argmax = tf.argmax(xy)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        matr = sess.run(xy, feed_dict={x: _x, y: _y})\n",
    "        # scalar = sess.run(argmax, feed_dict={x: _x, y: _y}) # hm, why does this work??\n",
    "        scalar = sess.run(argmax, feed_dict={xy: matr})\n",
    "\n",
    "print(matr)\n",
    "print(scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "y_true = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "w = tf.Variable([[0,0,0]], dtype=tf.float32, name = 'weights')\n",
    "b = tf.Variable(0, dtype=tf.float32, name = 'intercept')\n",
    "\n",
    "y_pred = tf.matmul(tf.transpose(w), x) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mean Square Error\n",
    "loss_mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Cross entropy (esp. for categorical data)\n",
    "loss_cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In Tensorflow gradients are calculated using \"automatic differentiation\"\n",
    "# learning rate - determines how large is the step in the direction of negative gradient\n",
    "# (we don't want to overshoot the minimum)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(vals):\n",
    "    plt.plot(vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(i):\n",
    "    return 1.0 / (1 + np.exp(-i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [array([[ 0.03611456,  0.05677616,  0.01069056]], dtype=float32), -0.021125071])\n",
      "(5, [array([[ 0.15908694,  0.25078008,  0.04631922]], dtype=float32), -0.093046457])\n",
      "(10, [array([[ 0.22413744,  0.35402197,  0.06443311]], dtype=float32), -0.130997])\n",
      "(15, [array([[ 0.26012734,  0.41144741,  0.07407537]], dtype=float32), -0.15188837])\n",
      "(20, [array([[ 0.28063321,  0.44432271,  0.0793708 ]], dtype=float32), -0.1637181])\n",
      "(25, [array([[ 0.29252315,  0.46346644,  0.08233628]], dtype=float32), -0.17053276])\n",
      "(30, [array([[ 0.29948896,  0.47472504,  0.08401754]], dtype=float32), -0.17449962])\n",
      "(35, [array([[ 0.30359507,  0.48138458,  0.08497842]], dtype=float32), -0.17682363])\n",
      "(40, [array([[ 0.30602437,  0.48533687,  0.08553064]], dtype=float32), -0.17819072])\n",
      "(45, [array([[ 0.30746484,  0.48768702,  0.08584926]], dtype=float32), -0.17899701])\n",
      "(50, [array([[ 0.30818272,  0.48886099,  0.08600436]], dtype=float32), -0.17939705])\n"
     ]
    }
   ],
   "source": [
    "N = 20000\n",
    "x_data = np.random.randn(N, 3)\n",
    "w_real = [0.3, 0.5, 0.1] # chosen weights\n",
    "b = -0.2                 # chosen bias\n",
    "wb = np.matmul(w_real, x_data.T) + b # (w, x_data.T): (1,3)x(3,N) -> 1xN\n",
    "\n",
    "y_data_pre_noise = sigmoid(wb)\n",
    "y_data = np.random.binomial(1, y_data_pre_noise)\n",
    "\n",
    "NUM_STEPS = 50\n",
    "LEARNING_RATE = 0.5\n",
    "\n",
    "g = tf.Graph()\n",
    "wb_ = []\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None,3])\n",
    "    y_true = tf.placeholder(tf.float32, shape=None)\n",
    "    \n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable([[0,0,0]], dtype=tf.float32, name = 'weights')\n",
    "        b = tf.Variable(0, dtype=tf.float32, name = 'bias')\n",
    "        y_pred = tf.matmul(w, tf.transpose(x)) + b\n",
    "\n",
    "    with tf.name_scope('loss') as scope:\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred) \n",
    "        loss = tf.reduce_mean(loss)\n",
    "  \n",
    "    with tf.name_scope('train') as scope:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE)\n",
    "        train = optimizer.minimize(loss)\n",
    "\n",
    "    # Initialize the vars and run the training\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)      \n",
    "        for step in range(NUM_STEPS):\n",
    "            sess.run(train, {x: x_data, y_true: y_data})\n",
    "            if (step % 5 == 0):\n",
    "                print(step, sess.run([w,b]))\n",
    "                wb_.append(sess.run([w,b]))\n",
    "\n",
    "        print(50, sess.run([w,b]))\n",
    "        \n",
    "        # The weights and bias are approaching the chosen/real [0.3, 0.5, 0.1] and -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
